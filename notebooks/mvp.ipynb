{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: Banking Marketing Campaign\n",
    "\n",
    "This notebook analyzes a banking marketing campaign dataset to predict whether customers will subscribe to a term deposit. We'll build and optimize a logistic regression model to classify customer responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports upfront\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data acquisition\n",
    "\n",
    "We'll start by loading the dataset from the provided URL and saving a local copy for future use.\n",
    "\n",
    "### 1.1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the provided URL\n",
    "data_url = 'https://raw.githubusercontent.com/4GeeksAcademy/logistic-regression-project-tutorial/main/bank-marketing-campaign-data.csv'\n",
    "data_df = pd.read_csv(data_url, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Save local copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory for raw data\n",
    "Path('../data/raw').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save a local copy of the raw data\n",
    "data_df.to_parquet('../data/raw/bank-marketing-campaign-data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation\n",
    "\n",
    "Before training our model, we need to prepare the data by splitting it into training and testing sets, and encoding categorical variables for use with scikit-learn.\n",
    "\n",
    "### 2.1. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (75%) and testing (25%) sets\n",
    "# This ensures we have unseen data to evaluate our final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature encoding\n",
    "\n",
    "Machine learning algorithms work with numerical data, so we need to convert categorical variables (strings) to numerical format using ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features with 'object' datatypes (string) which need encoding\n",
    "categorical_features = ['y','job','education','marital','default','housing','loan','contact','poutcome','day_of_week','month']\n",
    "\n",
    "# Instantiate a encoder\n",
    "\n",
    "# Encode the categorical features in the training and testing datasets\n",
    "\n",
    "# Inspect the result - there should be only float or int datatypes left\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training\n",
    "\n",
    "We'll establish baseline performance using simple models, then build and optimize a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Random model performance\n",
    "\n",
    "A random classifier serves as our weakest baseline - any useful model should significantly outperform random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random predictions for the testing set\n",
    "# This serves as a baseline to compare our model performance against\n",
    "\n",
    "# Calculate accuracy of random model\n",
    "\n",
    "# Store the accuracy in the results dictionary\n",
    "results['Random'] = accuracy\n",
    "\n",
    "print(f'Accuracy of random model: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Constant 'no' model performance\n",
    "\n",
    "Since this is a classification problem with imbalanced classes, we should check how well a model that always predicts the majority class would perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy if we always predict 'no' (the majority class)\n",
    "\n",
    "# Store the accuracy in the results dictionary\n",
    "results['Constant No'] = accuracy\n",
    "\n",
    "print(f'Accuracy of constant \"no\" model: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Logistic regression model performance\n",
    "\n",
    "Now we'll train a basic logistic regression model with default parameters to see how much improvement we get over the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a basic logistic regression model with default parameters\n",
    "\n",
    "# Make predictions on the testing set\n",
    "\n",
    "# Calculate accuracy of the test set predictions\n",
    "\n",
    "# Store the accuracy in the results dictionary\n",
    "results['Regression'] = accuracy\n",
    "\n",
    "print(f\"Testing accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Optimized logistic regression model performance\n",
    "\n",
    "To get the best performance, we'll use grid search with cross-validation to find the optimal hyperparameters for our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters to search over\n",
    "# These parameters can significantly affect model performance\n",
    "hyperparameters = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],  # Different optimization algorithms\n",
    "    'fit_intercept': [True, False],                 # Whether to include intercept term\n",
    "    'max_iter': [50, 100, 200, 400, 800]            # Maximum iterations for convergence\n",
    "}\n",
    "\n",
    "# Use grid search with cross-validation to find best hyperparameters\n",
    "# This systematically tests all combinations to find the optimal settings\n",
    "\n",
    "\n",
    "# Save the best model and parameter combination\n",
    "winning_parameters = grid.best_params_\n",
    "winning_model = grid.best_estimator_\n",
    "\n",
    "print(f'Best hyperparameters: {winning_parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the best model on the testing set\n",
    "\n",
    "# Store the accuracy in the results dictionary\n",
    "results['Optimized Regression'] = accuracy\n",
    "\n",
    "print(f'Testing accuracy of optimized model: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot to compare model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final model\n",
    "\n",
    "With the best hyperparameters identified, we'll train our final model and evaluate its performance on the test set. The confusion matrix will help us understand how well the model performs for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model with winning hyperparameters on complete training set\n",
    "\n",
    "# Calculate test set accuracy\n",
    "\n",
    "print(f'Final model test set accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display normalized confusion matrix\n",
    "cm = confusion_matrix(testing_df['y'], predictions, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No', 'Yes'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set (Normalized)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the models directory exists\n",
    "Path('../models/model.pkl').parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the final model\n",
    "with open('../models/model.pkl', 'wb') as output_file:\n",
    "    pickle.dump(winning_model, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
